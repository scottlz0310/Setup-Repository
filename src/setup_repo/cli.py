"""CLI ã‚³ãƒãƒ³ãƒ‰ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""

import argparse
import builtins
import os
import sys
from pathlib import Path

from .backup_manager import BackupManager
from .branch_cleanup import BranchCleanup
from .config import load_config
from .deploy_manager import DeployManager
from .migration_manager import MigrationManager
from .monitor_manager import MonitorManager
from .quality_metrics import QualityMetricsCollector
from .quality_trends import QualityTrendManager
from .security_helpers import safe_path_join
from .setup import run_interactive_setup
from .sync import sync_repositories
from .template_manager import TemplateManager

_original_print = builtins.print
builtins.print = lambda *args, **kwargs: _original_print(*args, **{**kwargs, "flush": True})

# Windowsç’°å¢ƒã§ã®Unicodeã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã‚’ä¿®æ­£
# pytestå®Ÿè¡Œä¸­ã¯æ¨™æº–å‡ºåŠ›ã®detachã‚’ã‚¹ã‚­ãƒƒãƒ—
if os.name == "nt" and os.environ.get("PYTEST_RUNNING") != "1":
    import codecs

    # æ—¢ã«detachã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    try:
        if hasattr(sys.stdout, "detach"):
            sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())  # type: ignore[union-attr]
    except (AttributeError, OSError):
        pass  # æ—¢ã«detachã•ã‚Œã¦ã„ã‚‹ã‹ã€åˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

    try:
        if hasattr(sys.stderr, "detach"):
            sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())  # type: ignore[union-attr]
    except (AttributeError, OSError):
        pass  # æ—¢ã«detachã•ã‚Œã¦ã„ã‚‹ã‹ã€åˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

# å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç„¡åŠ¹åŒ–ï¼ˆå…¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼‰
try:
    if hasattr(sys.stdout, "reconfigure"):
        sys.stdout.reconfigure(line_buffering=True)  # type: ignore[attr-defined]
    if hasattr(sys.stderr, "reconfigure"):
        sys.stderr.reconfigure(line_buffering=True)  # type: ignore[attr-defined]
except (AttributeError, OSError):
    pass  # Python 3.7ä»¥å‰ã¾ãŸã¯reconfigureãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—


def setup_cli(args) -> None:
    """åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚³ãƒãƒ³ãƒ‰"""
    run_interactive_setup()


def sync_cli(args) -> None:
    """ãƒªãƒã‚¸ãƒˆãƒªåŒæœŸã‚³ãƒãƒ³ãƒ‰"""
    config = load_config()

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§è¨­å®šã‚’ä¸Šæ›¸ã
    if args.owner:
        config["owner"] = args.owner
    if args.dest:
        config["dest"] = args.dest

    config.update(
        {
            "dry_run": args.dry_run,
            "force": args.force,
            "use_https": args.use_https or config.get("use_https", False),
            "sync_only": args.sync_only or config.get("sync_only", False),
            "auto_stash": args.auto_stash or config.get("auto_stash", False),
            "skip_uv_install": args.skip_uv_install or config.get("skip_uv_install", False),
        }
    )

    # ãƒªãƒã‚¸ãƒˆãƒªåŒæœŸå®Ÿè¡Œ
    sync_repositories(config)


def quality_cli(args) -> None:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚³ãƒãƒ³ãƒ‰"""
    if args.project_root:
        try:
            project_root = safe_path_join(Path.cwd(), args.project_root)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {e}") from e
    else:
        project_root = Path.cwd()
    collector = QualityMetricsCollector(project_root)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    metrics = collector.collect_all_metrics()

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    output_file = None
    if args.output:
        try:
            output_file = safe_path_join(project_root, args.output)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {e}") from e
    report_file = collector.save_metrics_report(metrics, output_file)

    print("\nå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å®Œäº†:")
    print(f"  å“è³ªã‚¹ã‚³ã‚¢: {metrics.get_quality_score():.1f}/100")
    print(f"  ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: {metrics.test_coverage:.1f}%")
    print(f"  Ruffã‚¨ãƒ©ãƒ¼: {metrics.ruff_issues}ä»¶")
    print(f"  Pyrightã‚¨ãƒ©ãƒ¼: {metrics.pyright_errors}ä»¶")
    # äº’æ›æ€§ã®ãŸã‚ mypy_errors ã‚‚è¡¨ç¤º
    print(f"  MyPyã‚¨ãƒ©ãƒ¼ (äº’æ›): {metrics.mypy_errors}ä»¶")
    print(f"  ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§: {metrics.security_vulnerabilities}ä»¶")
    print(f"  ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report_file}")

    # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
    if args.save_trend:
        output_dir = safe_path_join(project_root, "output/quality-trends")
        output_dir.mkdir(parents=True, exist_ok=True)
        trend_file = safe_path_join(output_dir, "trend-data.json")
        trend_manager = QualityTrendManager(trend_file)
        trend_manager.add_data_point(metrics)
        print("  ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã¾ã—ãŸ")

    # å“è³ªåŸºæº–ãƒã‚§ãƒƒã‚¯
    if not metrics.is_passing():
        print("\nâš ï¸  å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“")
        exit(1)
    else:
        print("\nâœ… å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™")


def trend_cli(args) -> None:
    """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚³ãƒãƒ³ãƒ‰"""
    if args.project_root:
        try:
            project_root = safe_path_join(Path.cwd(), args.project_root)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {e}") from e
    else:
        project_root = Path.cwd()

    if args.trend_file:
        try:
            trend_file = safe_path_join(project_root, args.trend_file)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {e}") from e
    else:
        output_dir = safe_path_join(project_root, "output/quality-trends")
        output_dir.mkdir(parents=True, exist_ok=True)
        trend_file = safe_path_join(output_dir, "trend-data.json")

    trend_manager = QualityTrendManager(trend_file)

    if args.action == "analyze":
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        analysis = trend_manager.analyze_trend(args.days)

        print("\n" + "=" * 60)
        print("ğŸ“ˆ å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
        print("=" * 60)
        print(f"åˆ†ææœŸé–“: {analysis.period_days}æ—¥")
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {analysis.data_points}ä»¶")
        print(f"å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {analysis.average_quality_score:.1f}%")
        print(f"å¹³å‡ã‚«ãƒãƒ¬ãƒƒã‚¸: {analysis.average_coverage:.1f}%")
        print(f"å“è³ªã‚¹ã‚³ã‚¢ãƒˆãƒ¬ãƒ³ãƒ‰: {analysis.quality_score_trend}")
        print(f"ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒˆãƒ¬ãƒ³ãƒ‰: {analysis.coverage_trend}")

        if analysis.recent_issues:
            print("\nğŸš¨ æœ€è¿‘ã®å•é¡Œ:")
            for issue in analysis.recent_issues:
                print(f"  - {issue}")

        print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
        for recommendation in analysis.recommendations:
            print(f"  - {recommendation}")

    elif args.action == "report":
        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if args.output:
            try:
                output_file = safe_path_join(project_root, args.output)
            except ValueError as e:
                raise ValueError(f"ä¸æ­£ãªå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {e}") from e
        else:
            output_dir = safe_path_join(project_root, "output")
            output_dir.mkdir(parents=True, exist_ok=True)
            output_file = safe_path_join(output_dir, "trend-report.html")
        report_file = trend_manager.generate_html_report(output_file)
        print(f"HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_file}")

    elif args.action == "clean":
        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤
        data_points = trend_manager.load_trend_data()
        if args.keep_days:
            from datetime import datetime, timedelta

            cutoff_date = datetime.now() - timedelta(days=args.keep_days)
            filtered_points = [
                point
                for point in data_points
                if datetime.fromisoformat(point.timestamp.replace("Z", "+00:00")) >= cutoff_date
            ]
            trend_manager.save_trend_data(filtered_points)
            removed_count = len(data_points) - len(filtered_points)
            print(f"{removed_count}ä»¶ã®å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            print("--keep-daysã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")


def template_cli(args) -> None:
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã‚³ãƒãƒ³ãƒ‰"""
    if args.project_root:
        try:
            project_root = safe_path_join(Path.cwd(), args.project_root)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {e}") from e
    else:
        project_root = Path.cwd()

    if args.action == "list":
        manager = TemplateManager(project_root)
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§è¡¨ç¤º
        templates = manager.list_templates()

        print("\nåˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ:")
        print("=" * 40)

        if templates["gitignore"]:
            print("\nğŸ“„ Gitignoreãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ:")
            for template in templates["gitignore"]:
                print(f"  - {template}")

        if templates["vscode"]:
            print("\nğŸ”§ VS Codeãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ:")
            for template in templates["vscode"]:
                print(f"  - {template}")

        if templates["custom"]:
            print("\nğŸ¨ ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ:")
            for template in templates["custom"]:
                print(f"  - {template}")

        if not any(templates.values()):
            print("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    elif args.action == "apply":
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé©ç”¨
        if not args.name:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return

        target_path = Path.cwd()
        if args.target:
            try:
                target_path = safe_path_join(Path.cwd(), args.target)
            except ValueError as e:
                raise ValueError(f"ä¸æ­£ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¹: {e}") from e

        # project_rootã¨target_pathã‚’åˆ†é›¢ã—ã¦ä½¿ç”¨
        manager = TemplateManager(project_root)

        try:
            if args.type == "gitignore":
                result_path = manager.apply_gitignore_template(args.name, target_path)
                print(f"âœ… Gitignoreãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{args.name}' ã‚’é©ç”¨ã—ã¾ã—ãŸ: {result_path}")
            elif args.type == "vscode":
                result_path = manager.apply_vscode_template(args.name, target_path)
                print(f"âœ… VS Codeãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{args.name}' ã‚’é©ç”¨ã—ã¾ã—ãŸ: {result_path}")
            elif args.type == "custom":
                result_path = manager.apply_custom_template(args.name, target_path)
                print(f"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{args.name}' ã‚’é©ç”¨ã—ã¾ã—ãŸ: {result_path}")
            else:
                print("ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ (gitignore/vscode/custom)")
        except FileNotFoundError as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé©ç”¨ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    elif args.action == "create":
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
        if not args.name or not args.source:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåã¨ã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return

        manager = TemplateManager(project_root)
        try:
            source_path = safe_path_join(project_root, args.source)
            result_path = manager.create_custom_template(args.name, source_path)
            print(f"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{args.name}' ã‚’ä½œæˆã—ã¾ã—ãŸ: {result_path}")
        except (FileNotFoundError, FileExistsError) as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    elif args.action == "remove":
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‰Šé™¤
        if not args.name:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return

        manager = TemplateManager(project_root)
        if manager.remove_template(args.name):
            print(f"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{args.name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{args.name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    else:
        print("ã‚¨ãƒ©ãƒ¼: ä¸æ­£ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚list/apply/create/remove ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")


def backup_cli(args) -> None:
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†ã‚³ãƒãƒ³ãƒ‰"""
    if args.project_root:
        try:
            project_root = safe_path_join(Path.cwd(), args.project_root)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {e}") from e
    else:
        project_root = Path.cwd()

    manager = BackupManager(project_root)

    if args.action == "create":
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        try:
            backup_path = manager.create_backup(args.name)
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¾ã—ãŸ: {backup_path}")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    elif args.action == "list":
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§
        backups = manager.list_backups()

        if not backups:
            print("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        print("\nåˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:")
        print("=" * 60)

        for backup in backups:
            size_mb = backup["file_size"] / (1024 * 1024)
            created_at = backup["created_at"][:19].replace("T", " ")
            print(f"\nğŸ’¾ {backup['name']}")
            print(f"  ä½œæˆæ—¥æ™‚: {created_at}")
            print(f"  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size_mb:.1f} MB")

            if backup.get("targets"):
                print("  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡:")
                for target in backup["targets"]:
                    target_size = target["size"] / 1024 if target["size"] > 0 else 0
                    print(f"    - {target['path']} ({target['type']}, {target_size:.1f} KB)")

    elif args.action == "restore":
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ
        if not args.name:
            print("ã‚¨ãƒ©ãƒ¼: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—åã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return

        target_path = None
        if args.target:
            try:
                target_path = safe_path_join(Path.cwd(), args.target)
            except ValueError as e:
                raise ValueError(f"ä¸æ­£ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¹: {e}") from e

        try:
            success = manager.restore_backup(args.name, target_path)
            if success:
                restore_path = target_path or project_root
                print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— '{args.name}' ã‚’å¾©å…ƒã—ã¾ã—ãŸ: {restore_path}")
                print("âš ï¸  æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ .restore_backup ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
        except (FileNotFoundError, RuntimeError) as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")

    elif args.action == "remove":
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
        if not args.name:
            print("ã‚¨ãƒ©ãƒ¼: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—åã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return

        if manager.remove_backup(args.name):
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— '{args.name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— '{args.name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    else:
        print("ã‚¨ãƒ©ãƒ¼: ä¸æ­£ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚create/list/restore/remove ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")


def monitor_cli(args) -> None:
    """ç›£è¦–ãƒ»ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚³ãƒãƒ³ãƒ‰"""
    if args.project_root:
        try:
            project_root = safe_path_join(Path.cwd(), args.project_root)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {e}") from e
    else:
        project_root = Path.cwd()

    manager = MonitorManager(project_root)

    if args.action == "health":
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        health_data = manager.run_health_check()

        print("\n" + "=" * 60)
        print("ğŸ¥ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯")
        print("=" * 60)
        print(f"å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {health_data['overall_status'].upper()}")
        print(f"ãƒã‚§ãƒƒã‚¯æ™‚åˆ»: {health_data['timestamp'][:19].replace('T', ' ')}")

        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        system = health_data["system"]
        print("\nğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
        print(f"  ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {system['platform']} {system['architecture']}")
        print(f"  Python: {system['python_version'].split()[0]}")

        # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
        resources = health_data["resources"]
        print("\nğŸ“Š ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³:")
        print(f"  CPUä½¿ç”¨ç‡: {resources['cpu_usage_percent']:.1f}%")
        print(
            f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {resources['memory_usage_percent']:.1f}% "
            f"({resources['memory_used_gb']:.1f}GB / {resources['memory_total_gb']:.1f}GB)"
        )
        print(
            f"  ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {resources['disk_usage_percent']:.1f}% "
            f"({resources['disk_used_gb']:.1f}GB / {resources['disk_total_gb']:.1f}GB)"
        )

        # ä¾å­˜é–¢ä¿‚
        deps = health_data["dependencies"]
        print("\nğŸ”§ ä¾å­˜é–¢ä¿‚:")
        print(f"  uv: {'âœ…' if deps['uv_available'] else 'âŒ'}")
        print(f"  Git: {'âœ…' if deps['git_available'] else 'âŒ'}")
        print(f"  Python (>=3.9): {'âœ…' if deps['python_version_supported'] else 'âŒ'}")

        for tool, info in deps["required_tools"].items():
            status = "âœ…" if info["available"] else "âŒ"
            version = f" ({info['version']})" if info["version"] else ""
            print(f"  {tool}: {status}{version}")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹
        project = health_data["project"]
        print("\nğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹:")
        print(f"  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {'âœ…' if project['config_exists'] else 'âŒ'}")
        print(f"  pyproject.toml: {'âœ…' if project['pyproject_exists'] else 'âŒ'}")
        print(f"  Gitãƒªãƒã‚¸ãƒˆãƒª: {'âœ…' if project['git_repo'] else 'âŒ'}")

        if project["quality_metrics"]:
            qm = project["quality_metrics"]
            print(f"  å“è³ªã‚¹ã‚³ã‚¢: {qm['quality_score']:.1f}/100")
            print(f"  ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: {qm['test_coverage']:.1f}%")
            print(f"  Ruffã‚¨ãƒ©ãƒ¼: {qm['ruff_issues']}ä»¶")
            print(f"  MyPyã‚¨ãƒ©ãƒ¼: {qm['mypy_errors']}ä»¶")
            print(f"  ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§: {qm['security_vulnerabilities']}ä»¶")

        # å•é¡Œã¨æ¨å¥¨äº‹é …
        if health_data["issues"]:
            print("\nğŸš¨ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
            for issue in health_data["issues"]:
                print(f"  - {issue}")

        if health_data["recommendations"]:
            print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for rec in health_data["recommendations"]:
                print(f"  - {rec}")

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        if args.output:
            try:
                output_dir = safe_path_join(project_root, "output")
                output_dir.mkdir(parents=True, exist_ok=True)
                output_file = safe_path_join(output_dir, args.output)
                with open(output_file, "w", encoding="utf-8") as f:
                    import json

                    json.dump(health_data, f, indent=2, ensure_ascii=False)
                print(f"\nğŸ“„ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    elif args.action == "performance":
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        perf_data = manager.run_performance_monitoring()

        print("\n" + "=" * 60)
        print("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–")
        print("=" * 60)
        print(f"ç›£è¦–æ™‚åˆ»: {perf_data['timestamp'][:19].replace('T', ' ')}")

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        sys_perf = perf_data["system_performance"]
        print("\nğŸ’» ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
        print(f"  CPUã‚³ã‚¢æ•°: {sys_perf['cpu_count']}")
        print(f"  CPUä½¿ç”¨ç‡: {sys_perf['cpu_usage']}")
        print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {sys_perf['memory']['percent']:.1f}%")
        print(f"  åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {sys_perf['memory']['available'] / (1024**3):.1f}GB")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        proj_perf = perf_data["project_performance"]
        print("\nğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {proj_perf['file_count']:,}")
        print(f"  ç·ã‚µã‚¤ã‚º: {proj_perf['total_size'] / (1024**2):.1f}MB")
        print(f"  Pythonãƒ•ã‚¡ã‚¤ãƒ«æ•°: {proj_perf['python_files']:,}")
        print(f"  ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {proj_perf['test_files']:,}")

        print("\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: output/monitoring/")

    elif args.action == "alerts":
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        alerts = manager.run_alert_check()

        print("\n" + "=" * 60)
        print("ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯")
        print("=" * 60)

        if not alerts:
            print("âœ… ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¢ãƒ©ãƒ¼ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“")
        else:
            print(f"âš ï¸  {len(alerts)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:\n")
            for alert in alerts:
                severity_icon = {
                    "critical": "ğŸ”´",
                    "high": "ğŸŸ ",
                    "warning": "ğŸŸ¡",
                    "info": "ğŸ”µ",
                }.get(alert["severity"], "âšª")
                print(f"  {severity_icon} [{alert['severity'].upper()}] {alert['message']}")
                print(f"    ã‚¿ã‚¤ãƒ—: {alert['type']}, æ™‚åˆ»: {alert['timestamp'][:19].replace('T', ' ')}")

            print("\nğŸ“„ ã‚¢ãƒ©ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: output/alerts/")

    elif args.action == "dashboard":
        # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        dashboard_data = manager.generate_dashboard_data()

        print("\n" + "=" * 60)
        print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        print("=" * 60)

        summary = dashboard_data["summary"]
        print(f"å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {summary['overall_status'].upper()}")
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {summary['active_alerts']}ä»¶")
        print(f"CPUä½¿ç”¨ç‡: {summary['cpu_usage']:.1f}%")
        print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {summary['memory_usage']:.1f}%")
        print(f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {summary['disk_usage']:.1f}%")

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        output_dir = safe_path_join(project_root, "output")
        output_dir.mkdir(parents=True, exist_ok=True)

        if args.output:
            try:
                output_file = safe_path_join(output_dir, args.output)
            except ValueError as e:
                raise ValueError(f"ä¸æ­£ãªå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {e}") from e
        else:
            output_file = safe_path_join(output_dir, "dashboard.json")

        try:
            with open(output_file, "w", encoding="utf-8") as f:
                import json

                json.dump(dashboard_data, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“„ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    else:
        print("ã‚¨ãƒ©ãƒ¼: ä¸æ­£ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚health/performance/alerts/dashboard ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")


def migration_cli(args) -> None:
    """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†ã‚³ãƒãƒ³ãƒ‰"""
    if args.project_root:
        try:
            project_root = safe_path_join(Path.cwd(), args.project_root)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {e}") from e
    else:
        project_root = Path.cwd()

    manager = MigrationManager(project_root)

    if args.action == "check":
        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¿…è¦æ€§ãƒã‚§ãƒƒã‚¯
        result = manager.check_migration_needed()

        print("\n" + "=" * 60)
        print("ğŸ”„ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯")
        print("=" * 60)
        print(f"ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {result['current_version']}")
        print(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³: {result['target_version']}")
        print(f"ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¿…è¦: {'ã¯ã„' if result['migration_needed'] else 'ã„ã„ãˆ'}")

        if result["changes"]:
            print("\nğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸå¤‰æ›´:")
            for change in result["changes"]:
                print(f"  - {change['description']}")
                print(f"    ã‚¿ã‚¤ãƒ—: {change['type']}")
        else:
            print("\nâœ… å¤‰æ›´ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    elif args.action == "run":
        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        print("\nğŸ”„ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­...")
        result = manager.run_migration(backup=not args.no_backup)

        if result["success"]:
            print(f"âœ… {result['message']}")
            if result.get("backup_path"):
                print(f"ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {result['backup_path']}")

            if result.get("migration_result", {}).get("migrations"):
                print("\nğŸ“‹ å®Ÿè¡Œã•ã‚ŒãŸãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:")
                for migration in result["migration_result"]["migrations"]:
                    print(f"  - {migration['description']}")
                    if migration.get("backup_file"):
                        print(f"    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {migration['backup_file']}")
        else:
            print(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {result['error']}")
            if result.get("backup_path"):
                print(f"ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒå¯èƒ½: {result['backup_path']}")
            exit(1)

    elif args.action == "rollback":
        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
        print("\nâª ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
        result = manager.rollback_migration(args.backup_name)

        if result["success"]:
            print(f"âœ… {result['message']}")
        else:
            print(f"âŒ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {result['error']}")
            exit(1)

    else:
        print("ã‚¨ãƒ©ãƒ¼: ä¸æ­£ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚check/run/rollback ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")


def deploy_cli(args) -> None:
    """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç®¡ç†ã‚³ãƒãƒ³ãƒ‰"""
    config = load_config()
    manager = DeployManager(config)

    if args.action == "prepare":
        # ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™
        print("\nğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™ã‚’é–‹å§‹ã—ã¾ã™...")
        if manager.prepare():
            print("âœ… ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("âŒ ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ")
            exit(1)

    elif args.action == "execute":
        # ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ
        environment = args.environment or "production"
        print(f"\nğŸš€ ç’°å¢ƒ '{environment}' ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’é–‹å§‹ã—ã¾ã™...")
        if manager.execute(environment):
            print("âœ… ãƒ‡ãƒ—ãƒ­ã‚¤ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("âŒ ãƒ‡ãƒ—ãƒ­ã‚¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
            exit(1)

    elif args.action == "rollback":
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        print("\nâª ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’é–‹å§‹ã—ã¾ã™...")
        if manager.rollback(args.deploy_id):
            print("âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("âŒ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ")
            exit(1)

    elif args.action == "list":
        # ãƒ‡ãƒ—ãƒ­ã‚¤å±¥æ­´ä¸€è¦§
        deployments = manager.list_deployments()

        if not deployments:
            print("ãƒ‡ãƒ—ãƒ­ã‚¤å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        print("\nğŸ“‹ ãƒ‡ãƒ—ãƒ­ã‚¤å±¥æ­´:")
        print("=" * 80)

        for deployment in reversed(deployments[-10:]):  # æœ€æ–°10ä»¶
            status_icon = "âœ…" if deployment["status"] == "success" else "âŒ"
            timestamp = deployment["timestamp"][:19].replace("T", " ")
            print(f"\n{status_icon} {deployment['deploy_id']}")
            print(f"  ç’°å¢ƒ: {deployment['environment']}")
            print(f"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {deployment['status']}")
            print(f"  æ™‚åˆ»: {timestamp}")
            print(f"  ã‚³ãƒŸãƒƒãƒˆ: {deployment['commit_hash'][:8]}")
            print(f"  ãƒ–ãƒ©ãƒ³ãƒ: {deployment['branch']}")

            if deployment.get("rollback_target"):
                print(f"  ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾è±¡: {deployment['rollback_target']}")

    else:
        print("ã‚¨ãƒ©ãƒ¼: ä¸æ­£ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚prepare/execute/rollback/list ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")


def cleanup_cli(args) -> None:
    """ãƒ–ãƒ©ãƒ³ãƒã‚¯ãƒªãƒ¼ãƒ³ãƒŠãƒƒãƒ—ã‚³ãƒãƒ³ãƒ‰"""
    if args.repo_path:
        try:
            repo_path = safe_path_join(Path.cwd(), args.repo_path)
        except ValueError as e:
            raise ValueError(f"ä¸æ­£ãªãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¹: {e}") from e
    else:
        repo_path = Path.cwd()

    if not (repo_path / ".git").exists():
        print("ã‚¨ãƒ©ãƒ¼: Gitãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        exit(1)

    cleanup = BranchCleanup(repo_path)

    if args.action == "list":
        # ãƒ–ãƒ©ãƒ³ãƒä¸€è¦§è¡¨ç¤º
        if args.merged:
            base_branch = args.base_branch or "origin/main"
            merged_branches = cleanup.list_merged_branches(base_branch)
            print(f"\nğŸ“‹ ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ–ãƒ©ãƒ³ãƒ ({base_branch}): {len(merged_branches)}ä»¶")
            for branch in merged_branches:
                print(f"   - {branch}")
        elif args.stale:
            days = args.days or 90
            stale_branches = cleanup.list_stale_branches(days)
            print(f"\nğŸ“‹ {days}æ—¥ä»¥ä¸Šæ›´æ–°ã•ã‚Œã¦ã„ãªã„ãƒ–ãƒ©ãƒ³ãƒ: {len(stale_branches)}ä»¶")
            for stale_branch in stale_branches:
                print(f"   - {stale_branch['name']} (æœ€çµ‚æ›´æ–°: {stale_branch['last_commit_date'][:10]})")
        else:
            all_branches = cleanup.list_remote_branches()
            print(f"\nğŸ“‹ ãƒªãƒ¢ãƒ¼ãƒˆãƒ–ãƒ©ãƒ³ãƒ: {len(all_branches)}ä»¶")
            for remote_branch in all_branches:
                print(f"   - {remote_branch['name']} (æœ€çµ‚æ›´æ–°: {remote_branch['last_commit_date'][:10]})")

    elif args.action == "clean":
        # ãƒ–ãƒ©ãƒ³ãƒã‚¯ãƒªãƒ¼ãƒ³ãƒŠãƒƒãƒ—å®Ÿè¡Œ
        result = None
        if args.merged:
            base_branch = args.base_branch or "origin/main"
            print(f"\nğŸ§¹ ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ–ãƒ©ãƒ³ãƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ãƒŠãƒƒãƒ—ã—ã¾ã™ (ãƒ™ãƒ¼ã‚¹: {base_branch})")
            result = cleanup.cleanup_merged_branches(
                base_branch=base_branch, dry_run=args.dry_run, auto_confirm=args.yes
            )
        elif args.stale:
            days = args.days or 90
            print(f"\nğŸ§¹ {days}æ—¥ä»¥ä¸Šæ›´æ–°ã•ã‚Œã¦ã„ãªã„ãƒ–ãƒ©ãƒ³ãƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ãƒŠãƒƒãƒ—ã—ã¾ã™")
            result = cleanup.cleanup_stale_branches(days=days, dry_run=args.dry_run, auto_confirm=args.yes)
        else:
            print("ã‚¨ãƒ©ãƒ¼: --merged ã¾ãŸã¯ --stale ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            exit(1)

        # çµæœè¡¨ç¤º
        if result is not None:
            print("\n" + "=" * 60)
            print("ğŸ“Š ã‚¯ãƒªãƒ¼ãƒ³ãƒŠãƒƒãƒ—çµæœ")
            print("=" * 60)
            print(f"å‰Šé™¤: {result['deleted']}ä»¶")
            print(f"å¤±æ•—: {result['failed']}ä»¶")
            print(f"ã‚¹ã‚­ãƒƒãƒ—: {result['skipped']}ä»¶")

            if result["branches"] and not args.dry_run:
                print("\nå‰Šé™¤ã•ã‚ŒãŸãƒ–ãƒ©ãƒ³ãƒ:")
                for branch_name in result["branches"]:
                    print(f"   - {branch_name}")

    else:
        print("ã‚¨ãƒ©ãƒ¼: ä¸æ­£ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚list/clean ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(
        description=("ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒªãƒã‚¸ãƒˆãƒª - GitHubãƒªãƒã‚¸ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»åŒæœŸãƒ„ãƒ¼ãƒ«"),
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  setup-repo setup              # åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
  setup-repo sync               # ãƒªãƒã‚¸ãƒˆãƒªåŒæœŸ
  setup-repo sync --dry-run     # å®Ÿè¡Œå†…å®¹ç¢ºèª
  setup-repo quality            # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
  setup-repo trend analyze      # å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
  setup-repo template list      # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§
  setup-repo backup create      # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
  setup-repo migration check    # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¿…è¦æ€§ãƒã‚§ãƒƒã‚¯
  setup-repo monitor health     # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
  setup-repo deploy prepare     # ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™
  setup-repo cleanup list       # ãƒªãƒ¢ãƒ¼ãƒˆãƒ–ãƒ©ãƒ³ãƒä¸€è¦§
  setup-repo cleanup clean --merged  # ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ–ãƒ©ãƒ³ãƒå‰Šé™¤
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰")

    # setupã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    setup_parser = subparsers.add_parser("setup", help="åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ")
    setup_parser.set_defaults(func=setup_cli)

    # syncã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    sync_parser = subparsers.add_parser("sync", help="ãƒªãƒã‚¸ãƒˆãƒªåŒæœŸã‚’å®Ÿè¡Œ")
    sync_parser.add_argument("--owner", help="GitHubã‚ªãƒ¼ãƒŠãƒ¼å")
    sync_parser.add_argument("--dest", help="ã‚¯ãƒ­ãƒ¼ãƒ³å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    sync_parser.add_argument("--dry-run", action="store_true", help="å®Ÿè¡Œå†…å®¹ã‚’è¡¨ç¤ºã®ã¿")
    sync_parser.add_argument("--force", action="store_true", help="å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    sync_parser.add_argument("--use-https", action="store_true", help="SSHã§ã¯ãªãHTTPSã§ã‚¯ãƒ­ãƒ¼ãƒ³")
    sync_parser.add_argument(
        "--sync-only",
        action="store_true",
        help="æ–°è¦ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’è¡Œã‚ãšã€æ—¢å­˜ãƒªãƒã‚¸ãƒˆãƒªã®ã¿æ›´æ–°",
    )
    sync_parser.add_argument("--auto-stash", action="store_true", help="ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ›´ã‚’è‡ªå‹•ã§stash")
    sync_parser.add_argument("--skip-uv-install", action="store_true", help="uvã®è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    sync_parser.set_defaults(func=sync_cli)

    # qualityã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    quality_parser = subparsers.add_parser("quality", help="å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚’å®Ÿè¡Œ")
    quality_parser.add_argument(
        "--project-root",
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    quality_parser.add_argument("--output", help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: quality-report.jsonï¼‰")
    quality_parser.add_argument("--save-trend", action="store_true", help="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã«çµæœã‚’ä¿å­˜")
    quality_parser.set_defaults(func=quality_cli)

    # trendã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    trend_parser = subparsers.add_parser("trend", help="å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œ")
    trend_parser.add_argument("action", choices=["analyze", "report", "clean"], help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    trend_parser.add_argument(
        "--project-root",
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    trend_parser.add_argument(
        "--trend-file",
        help="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: quality-trends/trend-data.jsonï¼‰",
    )
    trend_parser.add_argument("--days", type=int, default=30, help="åˆ†ææœŸé–“ï¼ˆæ—¥æ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30ï¼‰")
    trend_parser.add_argument(
        "--output",
        help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: quality-trends/trend-report.htmlï¼‰",
    )
    trend_parser.add_argument("--keep-days", type=int, help="ä¿æŒã™ã‚‹æ—¥æ•°ï¼ˆcleanã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”¨ï¼‰")
    trend_parser.set_defaults(func=trend_cli)

    # templateã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    template_parser = subparsers.add_parser("template", help="ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã‚’å®Ÿè¡Œ")
    template_parser.add_argument("action", choices=["list", "apply", "create", "remove"], help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    template_parser.add_argument("--name", help="ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå")
    template_parser.add_argument("--type", choices=["gitignore", "vscode", "custom"], help="ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—")
    template_parser.add_argument("--source", help="ã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹ï¼ˆcreateã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”¨ï¼‰")
    template_parser.add_argument("--target", help="é©ç”¨å…ˆãƒ‘ã‚¹ï¼ˆapplyã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”¨ï¼‰")
    template_parser.add_argument(
        "--project-root",
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    template_parser.set_defaults(func=template_cli)

    # backupã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    backup_parser = subparsers.add_parser("backup", help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†ã‚’å®Ÿè¡Œ")
    backup_parser.add_argument("action", choices=["create", "list", "restore", "remove"], help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    backup_parser.add_argument("--name", help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å")
    backup_parser.add_argument("--target", help="å¾©å…ƒå…ˆãƒ‘ã‚¹ï¼ˆrestoreã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”¨ï¼‰")
    backup_parser.add_argument(
        "--project-root",
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    backup_parser.set_defaults(func=backup_cli)

    # migrationã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    migration_parser = subparsers.add_parser("migration", help="ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†ã‚’å®Ÿè¡Œ")
    migration_parser.add_argument("action", choices=["check", "run", "rollback"], help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    migration_parser.add_argument("--backup-name", help="ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å")
    migration_parser.add_argument("--no-backup", action="store_true", help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ãªã„")
    migration_parser.add_argument(
        "--project-root",
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    migration_parser.set_defaults(func=migration_cli)

    # monitorã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    monitor_parser = subparsers.add_parser("monitor", help="ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãƒ»ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ")
    monitor_parser.add_argument(
        "action", choices=["health", "performance", "alerts", "dashboard"], help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"
    )
    monitor_parser.add_argument(
        "--project-root",
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    monitor_parser.add_argument("--output", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    monitor_parser.add_argument("--watch", action="store_true", help="ç¶™ç¶šç›£è¦–ãƒ¢ãƒ¼ãƒ‰")
    monitor_parser.add_argument("--interval", type=int, default=60, help="ç›£è¦–é–“éš”ï¼ˆç§’ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 60ï¼‰")
    monitor_parser.set_defaults(func=monitor_cli)

    # deployã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    deploy_parser = subparsers.add_parser("deploy", help="ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç®¡ç†ã‚’å®Ÿè¡Œ")
    deploy_parser.add_argument("action", choices=["prepare", "execute", "rollback", "list"], help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    deploy_parser.add_argument("--environment", help="ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: productionï¼‰")
    deploy_parser.add_argument("--deploy-id", help="ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾è±¡ã®ãƒ‡ãƒ—ãƒ­ã‚¤ID")
    deploy_parser.set_defaults(func=deploy_cli)

    # cleanupã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    cleanup_parser = subparsers.add_parser("cleanup", help="ãƒªãƒ¢ãƒ¼ãƒˆãƒ–ãƒ©ãƒ³ãƒã‚¯ãƒªãƒ¼ãƒ³ãƒŠãƒƒãƒ—ã‚’å®Ÿè¡Œ")
    cleanup_parser.add_argument("action", choices=["list", "clean"], help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    cleanup_parser.add_argument("--repo-path", help="ãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰")
    cleanup_parser.add_argument("--merged", action="store_true", help="ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ–ãƒ©ãƒ³ãƒã‚’å¯¾è±¡")
    cleanup_parser.add_argument("--stale", action="store_true", help="å¤ã„ãƒ–ãƒ©ãƒ³ãƒã‚’å¯¾è±¡")
    cleanup_parser.add_argument("--base-branch", help="ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: origin/mainï¼‰")
    cleanup_parser.add_argument("--days", type=int, help="å¤ã„ãƒ–ãƒ©ãƒ³ãƒã®æ—¥æ•°é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 90ï¼‰")
    cleanup_parser.add_argument("--dry-run", action="store_true", help="å®Ÿè¡Œå†…å®¹ã‚’è¡¨ç¤ºã®ã¿")
    cleanup_parser.add_argument("-y", "--yes", action="store_true", help="ç¢ºèªãªã—ã§å®Ÿè¡Œ")
    cleanup_parser.set_defaults(func=cleanup_cli)

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    # å¯¾å¿œã™ã‚‹é–¢æ•°ã‚’å®Ÿè¡Œ
    args.func(args)
