name: Monthly Quality Review

on:
  schedule:
    # æ¯æœˆ1æ—¥ã®åˆå‰9æ™‚ï¼ˆUTCï¼‰ã«å®Ÿè¡Œ
    - cron: "0 9 1 * *"
  workflow_dispatch:
    inputs:
      force_review:
        description: "å¼·åˆ¶çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œ"
        required: false
        default: "false"

jobs:
  monthly-review:
    name: Monthly Quality Review
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # å…¨å±¥æ­´ã‚’å–å¾—

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"

      - name: Set up Python
        run: uv python install 3.11

      - name: Create virtual environment
        run: uv venv --python 3.11

      - name: Install dependencies
        run: uv sync --dev

      - name: Generate comprehensive quality report
        run: |
          echo "ğŸ“Š æœˆæ¬¡å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."

          # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
          uv run python scripts/quality-monitor.py --collect-metrics

          # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
          uv run python scripts/quality-monitor.py --generate-trend-report

          # è²¬ä»»åˆ†é›¢åˆ†æ
          uv run python scripts/quality-monitor.py --analyze-responsibility > responsibility-analysis.txt

          # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
          uv run python scripts/coverage-monitor.py --analyze-trends > coverage-trends.txt

          # åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
          cat > monthly-quality-report.md << 'EOF'
          # ğŸ“Š æœˆæ¬¡å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ

          **ç”Ÿæˆæ—¥æ™‚**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **ãƒ¬ãƒ“ãƒ¥ãƒ¼æœŸé–“**: éå»30æ—¥é–“

          ## ğŸ¯ å“è³ªç›®æ¨™ã®é”æˆçŠ¶æ³

          EOF

          # ç¾åœ¨ã®å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
          if [ -f "quality-history/latest-metrics.json" ]; then
            uv run python -c "
          import json

          with open('quality-history/latest-metrics.json', 'r') as f:
              metrics = json.load(f)

          coverage = metrics['test_coverage']
          quality_score = metrics['quality_score']
          ruff_issues = metrics['ruff_issues']
          mypy_errors = metrics['mypy_errors']

          print(f'**ç¾åœ¨ã®ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸**: {coverage:.2f}% (ç›®æ¨™: 80%)')
          print(f'**å“è³ªã‚¹ã‚³ã‚¢**: {quality_score:.1f}/100 (ç›®æ¨™: 80)')
          print(f'**Ruffå•é¡Œ**: {ruff_issues}ä»¶ (ç›®æ¨™: â‰¤10ä»¶)')
          print(f'**MyPyã‚¨ãƒ©ãƒ¼**: {mypy_errors}ä»¶ (ç›®æ¨™: â‰¤5ä»¶)')
          print()

          # ç›®æ¨™é”æˆçŠ¶æ³
          goals_met = 0
          total_goals = 4

          if coverage >= 80:
              print('âœ… ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™é”æˆ')
              goals_met += 1
          else:
              print('âŒ ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™æœªé”æˆ')

          if quality_score >= 80:
              print('âœ… å“è³ªã‚¹ã‚³ã‚¢ç›®æ¨™é”æˆ')
              goals_met += 1
          else:
              print('âŒ å“è³ªã‚¹ã‚³ã‚¢ç›®æ¨™æœªé”æˆ')

          if ruff_issues <= 10:
              print('âœ… Ruffå•é¡Œç›®æ¨™é”æˆ')
              goals_met += 1
          else:
              print('âŒ Ruffå•é¡Œç›®æ¨™æœªé”æˆ')

          if mypy_errors <= 5:
              print('âœ… MyPyã‚¨ãƒ©ãƒ¼ç›®æ¨™é”æˆ')
              goals_met += 1
          else:
              print('âŒ MyPyã‚¨ãƒ©ãƒ¼ç›®æ¨™æœªé”æˆ')

          print()
          print(f'**ç›®æ¨™é”æˆç‡**: {goals_met}/{total_goals} ({goals_met/total_goals*100:.1f}%)')
          " >> monthly-quality-report.md
          fi

          echo "" >> monthly-quality-report.md
          echo "## ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ" >> monthly-quality-report.md
          echo "" >> monthly-quality-report.md
          cat coverage-trends.txt >> monthly-quality-report.md

          echo "" >> monthly-quality-report.md
          echo "## ğŸ—ï¸ è²¬ä»»åˆ†é›¢åˆ†æ" >> monthly-quality-report.md
          echo "" >> monthly-quality-report.md
          cat responsibility-analysis.txt >> monthly-quality-report.md

          # æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
          LATEST_TREND_REPORT=$(ls -t quality-reports/quality_trend_report_*.json 2>/dev/null | head -n1)
          if [ -f "$LATEST_TREND_REPORT" ]; then
            echo "" >> monthly-quality-report.md
            echo "## ğŸ’¡ æ”¹å–„ææ¡ˆ" >> monthly-quality-report.md
            echo "" >> monthly-quality-report.md

            uv run python -c "
          import json

          with open('$LATEST_TREND_REPORT', 'r') as f:
              report = json.load(f)

          suggestions = report.get('improvement_suggestions', [])
          if suggestions:
              for i, suggestion in enumerate(suggestions, 1):
                  print(f'{i}. {suggestion}')
          else:
              print('ç¾åœ¨ã€ç‰¹åˆ¥ãªæ”¹å–„ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å“è³ªåŸºæº–ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚')
          " >> monthly-quality-report.md
          fi

          echo "" >> monthly-quality-report.md
          echo "## ğŸ“‹ æ¬¡æœˆã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³" >> monthly-quality-report.md
          echo "" >> monthly-quality-report.md

          # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ
          uv run python -c "
          import json

          actions = []

          # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«åŸºã¥ã„ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆ
          try:
              with open('quality-history/latest-metrics.json', 'r') as f:
                  metrics = json.load(f)

              if metrics['test_coverage'] < 80:
                  actions.append('ğŸ¯ ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’80%ä»¥ä¸Šã«å‘ä¸Šã•ã›ã‚‹')
                  actions.append('ğŸ“ ä½ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç‰¹å®šã¨ãƒ†ã‚¹ãƒˆè¿½åŠ ')

              if metrics['quality_score'] < 80:
                  actions.append('ğŸ”§ å“è³ªã‚¹ã‚³ã‚¢å‘ä¸Šã®ãŸã‚ã®åŒ…æ‹¬çš„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°')

              if metrics['ruff_issues'] > 10:
                  actions.append('ğŸ§¹ Ruffãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°å•é¡Œã®è§£æ±º')
                  actions.append('ğŸ“ ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®å¾¹åº•')

              if metrics['mypy_errors'] > 5:
                  actions.append('ğŸ” å‹ãƒ’ãƒ³ãƒˆã®è¿½åŠ ã¨MyPyã‚¨ãƒ©ãƒ¼ã®è§£æ±º')
                  actions.append('ğŸ“š å‹å®‰å…¨æ€§å‘ä¸Šã®ãŸã‚ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™')

              # è²¬ä»»åˆ†é›¢ã«é–¢ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
              actions.append('ğŸ—ï¸ å¤§ããªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆ†å‰²æ¤œè¨')
              actions.append('ğŸ“Š æœˆæ¬¡å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ã®ç¶™ç¶š')
              actions.append('ğŸ”„ ç¶™ç¶šçš„æ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹ã®è¦‹ç›´ã—')

              if not actions:
                  actions.append('âœ… ç¾åœ¨ã®å“è³ªãƒ¬ãƒ™ãƒ«ã‚’ç¶­æŒ')
                  actions.append('ğŸš€ æ–°æ©Ÿèƒ½é–‹ç™ºæ™‚ã®å“è³ªåŸºæº–éµå®ˆ')

              for i, action in enumerate(actions, 1):
                  print(f'{i}. {action}')

          except Exception as e:
              print('1. å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèª')
              print('2. åŸºæœ¬çš„ãªå“è³ªã‚²ãƒ¼ãƒˆã®è¨­å®š')
              print('3. ç¶™ç¶šçš„ç›£è¦–ä½“åˆ¶ã®æ§‹ç¯‰')
          " >> monthly-quality-report.md

          echo "" >> monthly-quality-report.md
          echo "---" >> monthly-quality-report.md
          echo "*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚è©³ç´°ãªåˆ†æçµæœã¯ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚*" >> monthly-quality-report.md

      - name: Generate quality dashboard data
        run: |
          echo "ğŸ“Š å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­..."

          # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ã®JSONãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
          uv run python -c "
          import json
          import os
          from datetime import datetime
          from pathlib import Path

          dashboard_data = {
              'generated_at': datetime.now().isoformat(),
              'month': datetime.now().strftime('%Y-%m'),
              'summary': {},
              'trends': {},
              'alerts': []
          }

          # æœ€æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
          try:
              with open('quality-history/latest-metrics.json', 'r') as f:
                  latest_metrics = json.load(f)

              dashboard_data['summary'] = {
                  'coverage': latest_metrics['test_coverage'],
                  'quality_score': latest_metrics['quality_score'],
                  'ruff_issues': latest_metrics['ruff_issues'],
                  'mypy_errors': latest_metrics['mypy_errors'],
                  'test_passed': latest_metrics['test_passed'],
                  'test_failed': latest_metrics['test_failed']
              }

              # ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ç”Ÿæˆ
              if latest_metrics['test_coverage'] < 80:
                  dashboard_data['alerts'].append({
                      'type': 'warning',
                      'message': f\"ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒç›®æ¨™ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™: {latest_metrics['test_coverage']:.2f}%\"
                  })

              if latest_metrics['quality_score'] < 80:
                  dashboard_data['alerts'].append({
                      'type': 'error',
                      'message': f\"å“è³ªã‚¹ã‚³ã‚¢ãŒç›®æ¨™ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™: {latest_metrics['quality_score']:.1f}\"
                  })

          except Exception as e:
              dashboard_data['alerts'].append({
                  'type': 'error',
                  'message': f'ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}'
              })

          # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
          with open('quality-dashboard.json', 'w') as f:
              json.dump(dashboard_data, f, indent=2)

          print('å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ')
          "

      - name: Upload monthly review artifacts
        uses: actions/upload-artifact@v4
        with:
          name: monthly-quality-review
          path: |
            monthly-quality-report.md
            quality-dashboard.json
            quality-history/
            quality-reports/
            responsibility-analysis.txt
            coverage-trends.txt
          retention-days: 365 # 1å¹´é–“ä¿æŒ

      - name: Create GitHub Issue for review
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try {
              const report = fs.readFileSync('monthly-quality-report.md', 'utf8');
              const dashboardData = JSON.parse(fs.readFileSync('quality-dashboard.json', 'utf8'));

              const issueTitle = `æœˆæ¬¡å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ - ${dashboardData.month}`;
              const issueBody = `${report}

            ## ğŸ“ é–¢é€£ãƒªãƒ³ã‚¯
            - [å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            - [è©³ç´°ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})

            ## ğŸ‘¥ ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‹…å½“è€…
            @${context.repo.owner}

            ã“ã®Issueã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†å¾Œã«ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¦ãã ã•ã„ã€‚`;

              const issue = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['quality-review', 'monthly-review', 'automated']
              });

              console.log(`æœˆæ¬¡å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼Issueã‚’ä½œæˆã—ã¾ã—ãŸ: #${issue.data.number}`);
            } catch (error) {
              console.log('Issueä½œæˆã«å¤±æ•—:', error);
            }

      - name: Send quality alerts
        if: always()
        run: |
          echo "ğŸš¨ å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ä¸­..."

          # å“è³ªã‚²ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
          echo "ğŸ’ª å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™"
          if ! uv run python scripts/quality-monitor.py --check-gates; then
            echo "âŒ å“è³ªã‚²ãƒ¼ãƒˆã‚’é€šéã§ãã¾ã›ã‚“ã§ã—ãŸ"

            # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å†…å®¹ã‚’è¡¨ç¤º
            if [ -f "quality_alert.txt" ]; then
              echo "å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆå†…å®¹:"
              cat quality_alert.txt
            fi

            echo "âŒ é‡å¤§ãªå“è³ªå•é¡ŒãŒæ¤œå‡ºã•ã‚ŒãŸãŸã‚ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åœæ­¢ã—ã¾ã™"
            exit 1
          else
            echo "âœ… å“è³ªã‚²ãƒ¼ãƒˆã‚’é€šéã—ã¾ã—ãŸ"
          fi
