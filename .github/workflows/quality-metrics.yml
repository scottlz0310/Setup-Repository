name: Quality Metrics Collection

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # æ¯æ—¥åˆå‰2æ™‚ï¼ˆUTCï¼‰ã«å®Ÿè¡Œ
    - cron: "0 2 * * *"
  workflow_dispatch:

jobs:
  collect-metrics:
    name: Collect Quality Metrics
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # å±¥æ­´æ¯”è¼ƒã®ãŸã‚å…¨å±¥æ­´ã‚’å–å¾—

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"

      - name: Set up Python
        run: uv python install 3.11

      - name: Create virtual environment
        run: uv venv --python 3.11

      - name: Install dependencies
        run: uv sync --dev

      - name: Run quality analysis
        run: |
          echo "ğŸ” å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ä¸­..."

          # ã‚«ãƒãƒ¬ãƒƒã‚¸ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
          uv run python scripts/coverage-monitor.py --generate-report

          # Ruffã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯
          echo "ğŸ“ Ruffãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°å®Ÿè¡Œä¸­..."
          if ! uv run ruff check . --output-format=json > ruff-report.json; then
            echo "âŒ Ruffãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
            exit 1
          fi

          # MyPyã«ã‚ˆã‚‹å‹ãƒã‚§ãƒƒã‚¯
          echo "ğŸ” MyPyå‹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­..."
          if ! uv run mypy src/ --json-report mypy-report.json; then
            echo "âŒ MyPyå‹ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
            exit 1
          fi

          # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
          echo "ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­..."
          if ! uv run pytest tests/ \
            --json-report --json-report-file=test-report.json \
            --cov=src/setup_repo \
            --cov-report=json:coverage.json \
            -v; then
            echo "âŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ"
            exit 1
          fi

      - name: Generate quality metrics summary
        run: |
          echo "ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­..."

          # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
          uv run python -c "
          import json
          import os
          from datetime import datetime
          from pathlib import Path

          # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
          metrics = {
              'timestamp': datetime.now().isoformat(),
              'commit_sha': os.environ.get('GITHUB_SHA', 'unknown'),
              'branch': os.environ.get('GITHUB_REF_NAME', 'unknown'),
              'ruff_issues': 0,
              'mypy_errors': 0,
              'test_passed': 0,
              'test_failed': 0,
              'test_coverage': 0.0
          }

          # Ruffãƒ¬ãƒãƒ¼ãƒˆã‚’è§£æ
          try:
              with open('ruff-report.json', 'r') as f:
                  ruff_data = json.load(f)
              metrics['ruff_issues'] = len(ruff_data)
          except:
              pass

          # MyPyãƒ¬ãƒãƒ¼ãƒˆã‚’è§£æ
          try:
              with open('mypy-report.json', 'r') as f:
                  mypy_data = json.load(f)
              metrics['mypy_errors'] = len(mypy_data.get('errors', []))
          except:
              pass

          # ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’è§£æ
          try:
              with open('test-report.json', 'r') as f:
                  test_data = json.load(f)
              summary = test_data.get('summary', {})
              metrics['test_passed'] = summary.get('passed', 0)
              metrics['test_failed'] = summary.get('failed', 0)
          except:
              pass

          # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
          try:
              with open('coverage.json', 'r') as f:
                  cov_data = json.load(f)
              metrics['test_coverage'] = cov_data['totals']['percent_covered']
          except:
              pass

          # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
          with open('quality-metrics.json', 'w') as f:
              json.dump(metrics, f, indent=2)

          # ã‚µãƒãƒªãƒ¼ã‚’Markdownå½¢å¼ã§ç”Ÿæˆ
          with open('quality-summary.md', 'w') as f:
              f.write('# ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼\\n\\n')
              f.write(f'**å®Ÿè¡Œæ—¥æ™‚**: {metrics[\"timestamp\"]}\\n')
              f.write(f'**ã‚³ãƒŸãƒƒãƒˆ**: {metrics[\"commit_sha\"][:8]}\\n')
              f.write(f'**ãƒ–ãƒ©ãƒ³ãƒ**: {metrics[\"branch\"]}\\n\\n')

              f.write('## ãƒ¡ãƒˆãƒªã‚¯ã‚¹\\n\\n')
              f.write(f'- **ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸**: {metrics[\"test_coverage\"]:.2f}%\\n')
              f.write(f'- **ãƒ†ã‚¹ãƒˆçµæœ**: {metrics[\"test_passed\"]} æˆåŠŸ, {metrics[\"test_failed\"]} å¤±æ•—\\n')
              f.write(f'- **Ruffå•é¡Œ**: {metrics[\"ruff_issues\"]} ä»¶\\n')
              f.write(f'- **MyPyã‚¨ãƒ©ãƒ¼**: {metrics[\"mypy_errors\"]} ä»¶\\n\\n')

              # å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
              quality_score = 100
              if metrics['test_coverage'] < 80:
                  quality_score -= (80 - metrics['test_coverage']) * 2
              quality_score -= metrics['ruff_issues'] * 0.5
              quality_score -= metrics['mypy_errors'] * 1
              quality_score -= metrics['test_failed'] * 5
              quality_score = max(0, quality_score)

              f.write(f'## å“è³ªã‚¹ã‚³ã‚¢: {quality_score:.1f}/100\\n\\n')

              if quality_score >= 90:
                  f.write('âœ… **å„ªç§€**: å“è³ªåŸºæº–ã‚’å¤§å¹…ã«ä¸Šå›ã£ã¦ã„ã¾ã™\\n')
              elif quality_score >= 80:
                  f.write('âœ… **è‰¯å¥½**: å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™\\n')
              elif quality_score >= 70:
                  f.write('âš ï¸ **æ³¨æ„**: å“è³ªæ”¹å–„ãŒæ¨å¥¨ã•ã‚Œã¾ã™\\n')
              else:
                  f.write('âŒ **è¦æ”¹å–„**: å“è³ªåŸºæº–ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™\\n')

          print('å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã—ã¾ã—ãŸ')
          "

      - name: Store metrics history
        run: |
          echo "ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ã‚’ä¿å­˜ä¸­..."

          # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
          mkdir -p quality-history

          # æ—¥ä»˜ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜
          DATE=$(date +%Y%m%d_%H%M%S)
          cp quality-metrics.json quality-history/metrics_${DATE}.json

          # æœ€æ–°ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ›´æ–°
          cp quality-metrics.json quality-history/latest-metrics.json

      - name: Compare with baseline
        if: github.event_name == 'pull_request'
        run: |
          echo "ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒä¸­..."

          # ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒã‚’ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ
          git checkout ${{ github.event.pull_request.base.sha }}

          # ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ï¼ˆã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼‰
          uv run python scripts/coverage-monitor.py --generate-report || true
          uv run ruff check . --output-format=json > base-ruff-report.json || true
          uv run mypy src/ --json-report base-mypy-report.json || true
          uv run pytest tests/ --json-report --json-report-file=base-test-report.json --cov=src/setup_repo --cov-report=json:base-coverage.json || true

          # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒã«æˆ»ã‚‹
          git checkout ${{ github.event.pull_request.head.sha }}

          # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
          uv run python -c "
          import json
          import os

          def load_json_safe(filename):
              try:
                  with open(filename, 'r') as f:
                      return json.load(f)
              except:
                  return {}

          # ç¾åœ¨ã¨ãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
          current = load_json_safe('quality-metrics.json')

          # ãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç”Ÿæˆ
          base_metrics = {
              'ruff_issues': 0,
              'mypy_errors': 0,
              'test_coverage': 0.0
          }

          base_ruff = load_json_safe('base-ruff-report.json')
          if isinstance(base_ruff, list):
              base_metrics['ruff_issues'] = len(base_ruff)

          base_mypy = load_json_safe('base-mypy-report.json')
          base_metrics['mypy_errors'] = len(base_mypy.get('errors', []))

          base_cov = load_json_safe('base-coverage.json')
          if 'totals' in base_cov:
              base_metrics['test_coverage'] = base_cov['totals']['percent_covered']

          # æ¯”è¼ƒçµæœã‚’ç”Ÿæˆ
          comparison = {
              'coverage_diff': current.get('test_coverage', 0) - base_metrics['test_coverage'],
              'ruff_diff': current.get('ruff_issues', 0) - base_metrics['ruff_issues'],
              'mypy_diff': current.get('mypy_errors', 0) - base_metrics['mypy_errors']
          }

          # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownå½¢å¼ã§ç”Ÿæˆ
          with open('quality-comparison.md', 'w') as f:
              f.write('# ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒ\\n\\n')
              f.write('## ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒã¨ã®æ¯”è¼ƒ\\n\\n')

              # ã‚«ãƒãƒ¬ãƒƒã‚¸æ¯”è¼ƒ
              cov_diff = comparison['coverage_diff']
              cov_icon = 'âœ…' if cov_diff >= 0 else 'âš ï¸' if cov_diff > -5 else 'âŒ'
              f.write(f'{cov_icon} **ã‚«ãƒãƒ¬ãƒƒã‚¸**: {cov_diff:+.2f}% ({current.get(\"test_coverage\", 0):.2f}% vs {base_metrics[\"test_coverage\"]:.2f}%)\\n')

              # Ruffå•é¡Œæ¯”è¼ƒ
              ruff_diff = comparison['ruff_diff']
              ruff_icon = 'âœ…' if ruff_diff <= 0 else 'âš ï¸' if ruff_diff <= 5 else 'âŒ'
              f.write(f'{ruff_icon} **Ruffå•é¡Œ**: {ruff_diff:+d} ä»¶ ({current.get(\"ruff_issues\", 0)} vs {base_metrics[\"ruff_issues\"]})\\n')

              # MyPyã‚¨ãƒ©ãƒ¼æ¯”è¼ƒ
              mypy_diff = comparison['mypy_diff']
              mypy_icon = 'âœ…' if mypy_diff <= 0 else 'âš ï¸' if mypy_diff <= 3 else 'âŒ'
              f.write(f'{mypy_icon} **MyPyã‚¨ãƒ©ãƒ¼**: {mypy_diff:+d} ä»¶ ({current.get(\"mypy_errors\", 0)} vs {base_metrics[\"mypy_errors\"]})\\n\\n')

              # ç·åˆåˆ¤å®š
              if cov_diff >= 0 and ruff_diff <= 0 and mypy_diff <= 0:
                  f.write('âœ… **ç·åˆåˆ¤å®š**: å“è³ªãŒå‘ä¸Šã¾ãŸã¯ç¶­æŒã•ã‚Œã¦ã„ã¾ã™\\n')
              elif cov_diff >= -2 and ruff_diff <= 5 and mypy_diff <= 3:
                  f.write('âš ï¸ **ç·åˆåˆ¤å®š**: è»½å¾®ãªå“è³ªä½ä¸‹ãŒã‚ã‚Šã¾ã™\\n')
              else:
                  f.write('âŒ **ç·åˆåˆ¤å®š**: å“è³ªãŒå¤§å¹…ã«ä½ä¸‹ã—ã¦ã„ã¾ã™\\n')

          print('å“è³ªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ')
          "

      - name: Upload quality artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-metrics
          path: |
            quality-metrics.json
            quality-summary.md
            quality-comparison.md
            quality-history/
            ruff-report.json
            mypy-report.json
            test-report.json
          retention-days: 90

      - name: Publish quality summary
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            try {
              let summary = '';

              // å“è³ªã‚µãƒãƒªãƒ¼ã‚’èª­ã¿è¾¼ã¿
              if (fs.existsSync('quality-summary.md')) {
                summary += fs.readFileSync('quality-summary.md', 'utf8') + '\\n\\n';
              }

              // æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
              if (fs.existsSync('quality-comparison.md')) {
                summary += fs.readFileSync('quality-comparison.md', 'utf8');
              }

              if (summary) {
                github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: summary
                });
              }
            } catch (error) {
              console.log('å“è³ªã‚µãƒãƒªãƒ¼ã®æŠ•ç¨¿ã«å¤±æ•—:', error);
            }

      - name: Check quality gates
        run: |
          echo "ğŸšª å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ä¸­..."

          # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
          COVERAGE=$(uv run python -c "import json; data=json.load(open('quality-metrics.json')); print(data['test_coverage'])")
          RUFF_ISSUES=$(uv run python -c "import json; data=json.load(open('quality-metrics.json')); print(data['ruff_issues'])")
          MYPY_ERRORS=$(uv run python -c "import json; data=json.load(open('quality-metrics.json')); print(data['mypy_errors'])")
          TEST_FAILED=$(uv run python -c "import json; data=json.load(open('quality-metrics.json')); print(data['test_failed'])")

          echo "å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹:"
          echo "  ã‚«ãƒãƒ¬ãƒƒã‚¸: ${COVERAGE}%"
          echo "  Ruffå•é¡Œ: ${RUFF_ISSUES}ä»¶"
          echo "  MyPyã‚¨ãƒ©ãƒ¼: ${MYPY_ERRORS}ä»¶"
          echo "  ãƒ†ã‚¹ãƒˆå¤±æ•—: ${TEST_FAILED}ä»¶"

          # å“è³ªã‚²ãƒ¼ãƒˆã®åˆ¤å®š
          GATE_PASSED=true

          if (( $(echo "$COVERAGE < 80" | bc -l) )); then
            echo "âŒ ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ80%ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™: ${COVERAGE}%"
            GATE_PASSED=false
          fi

          if [ "$TEST_FAILED" -gt 0 ]; then
            echo "âŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¦ã„ã¾ã™: ${TEST_FAILED}ä»¶"
            GATE_PASSED=false
          fi

          if [ "$RUFF_ISSUES" -gt 10 ]; then
            echo "âš ï¸ Ruffå•é¡ŒãŒå¤šã™ãã¾ã™: ${RUFF_ISSUES}ä»¶"
          fi

          if [ "$MYPY_ERRORS" -gt 5 ]; then
            echo "âš ï¸ MyPyã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã¾ã™: ${MYPY_ERRORS}ä»¶"
          fi

          if [ "$GATE_PASSED" = true ]; then
            echo "âœ… å“è³ªã‚²ãƒ¼ãƒˆã‚’é€šéã—ã¾ã—ãŸ"
          else
            echo "âŒ å“è³ªã‚²ãƒ¼ãƒˆã‚’é€šéã§ãã¾ã›ã‚“ã§ã—ãŸ"
            exit 1
          fi
